{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Residual Network 101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanMarcelKezmann/Residual-Network-Architectures/blob/master/Residual_Network_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMW51RT1WWae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Flatten, Activation, BatchNormalization, Conv2D, ZeroPadding2D, AveragePooling2D\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.set_image_data_format(\"channels_last\")\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "from IPython.display import SVG\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jvz0-q_XaOS",
        "colab_type": "text"
      },
      "source": [
        "# Create all Building Blocks\n",
        "\n",
        "## Identity Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IomCIsabXRLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
        "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
        "\n",
        "    # Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value as Shortcut\n",
        "    X_shortcut = X\n",
        "\n",
        "    # Main Path\n",
        "    # First Component of Main Path\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name=conv_name_base + \"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + \"2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    # Second Component of Main Path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding=\"same\", name=conv_name_base + \"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + \"2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    # Third Component of Main Path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name=conv_name_base + \"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + \"2c\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    # Final Step: Add the Shortcut to the Main Path\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUdfFJR7bUSN",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLCpRXW-bTGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, strides=2):\n",
        "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
        "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
        "\n",
        "    # Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save input value as shortcut\n",
        "    X_shortcut = X\n",
        "\n",
        "    # Main Path\n",
        "    # First Component of Main Path\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(strides, strides), padding=\"valid\", name=conv_name_base + \"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + \"2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    # Second Component of Main Path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding=\"same\", name=conv_name_base + \"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + \"2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    # Third Component of Main Path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name=conv_name_base + \"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + \"2c\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    # Shortcut Path\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(strides, strides), padding=\"valid\", name=conv_name_base + \"1\", kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + \"1\")(X_shortcut)\n",
        "\n",
        "    # Final Step: Add shortcut path to main path\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7AZ88OHdv9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.reset_default_graph()\n",
        "\n",
        "# with tf.Session() as sess:\n",
        "#     np.random.seed(1)\n",
        "#     A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
        "#     X = np.random.randn(3, 4, 4, 6)\n",
        "#     A = identity_block(A_prev, f=3, filters=[2, 4, 6], stage=1, block=\"a\")\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#     out = sess.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
        "#     print(\"out = \" + str(out[0][0][0][0]))\n",
        "#     print(np.size(out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxnaSgoANf6g",
        "colab_type": "text"
      },
      "source": [
        "## ResNet 101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY02C9hyIex8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet101(input_shape=(224, 224, 3), classes=100):\n",
        "    # Define Input as tensor with input_shape as shape\n",
        "    # Default shape: (224x224x3)\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # ZeroPadding2D(((7 - 1) / 2, (7 - 1) / 2))(X_input)\n",
        "    # Output shape: (230x230x3)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    # Output shape after Conv2D: (112x112x64)\n",
        "    X = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), name=\"conv1\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    # Output shape after MaxPooling2D: (56x56x64)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(X)\n",
        "\n",
        "    # Stage 2\n",
        "    # Output shape after stage 2: (56x56x256)\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"a\", strides=1)\n",
        "    X = identity_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"b\")\n",
        "    X = identity_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"c\")\n",
        "    \n",
        "    # Stage 3\n",
        "    # Output shape after stage 3: (28x28x512)\n",
        "    X = convolutional_block(X, f=4, filters=[128, 128, 512], stage=3, block=\"a\", strides=2)\n",
        "    X = identity_block(X, f=4, filters=[128, 128, 512], stage=3, block=\"b\")\n",
        "    X = identity_block(X, f=4, filters=[128, 128, 512], stage=3, block=\"c\")\n",
        "    X = identity_block(X, f=4, filters=[128, 128, 512], stage=3, block=\"d\")\n",
        "\n",
        "    # Stage 4\n",
        "    # Output shape after stage 4: (14x14x1024)\n",
        "    X = convolutional_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"a\", strides=2)\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"b\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"c\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"d\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"e\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"f\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"g\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"h\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"i\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"j\")\n",
        "\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"k\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"l\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"m\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"n\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"o\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"p\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"q\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"r\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"s\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"t\")\n",
        "\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"u\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"v\")\n",
        "    X = identity_block(X, f=6, filters=[256, 256, 1024], stage=4, block=\"w\")\n",
        "\n",
        "    # Stage 5\n",
        "    # Output shape after stage 5: (7x7x2048)\n",
        "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"a\", strides=2)\n",
        "    X = identity_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"b\")\n",
        "    X = identity_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"c\")\n",
        "\n",
        "    # Final Stage\n",
        "    # Output shape after Dense Layer: (classes)\n",
        "#     X = AveragePooling2D((2, 2), name=\"avg_pool\")(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation=\"softmax\", name=\"fc\" + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=X_input, outputs=X, name=\"ResNet101\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRr4JjxyQ4zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def random_mini_batches(X, y, mini_batch_size=32, seed=0):\n",
        "#     m = X.shape[0]\n",
        "#     mini_batches = []\n",
        "#     np.random.seed(seed)\n",
        "\n",
        "#     # Step 1: shuffle (X, y)\n",
        "#     permutation = list(np.random.permutation(m))\n",
        "#     shuffled_X = X[permutation, :, :, :]\n",
        "#     shuffled_y = X[permutation, :]\n",
        "\n",
        "#     # Step 2: partition (shuffled_X, shuffled_y)\n",
        "#     num_complete_minibatches = math.floor(m / mini_batch_size)\n",
        "#     for k in range(0, num_complete_minibatches):\n",
        "#         mini_batch_X = shuffled_X[k * mini_batch_size:(k + 1) * mini_batch_size, :, :, :]\n",
        "#         mini_batch_y = shuffled_y[k * mini_batch_size:(k + 1) * mini_batch_size, :]\n",
        "#         mini_batch = (mini_batch_X, mini_batch_y)\n",
        "#         mini_batches.append(mini_batch)\n",
        "\n",
        "#     # handling the rest case\n",
        "#     if m % mini_batch_size != 0:\n",
        "#         mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size:m, :, :, :]\n",
        "#         mini_batch_y = shuffled_y[num_complete_minibatches * mini_batch_size:m, :]\n",
        "#         mini_batch = (mini_batch_X, mini_batch_y)\n",
        "#         mini_batches.append(mini_batch)\n",
        "\n",
        "#     return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "820o8-pzSa4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def convert_to_one_hot(y, classes):\n",
        "#     y = np.eye(int(classes))[y.reshape(-1)].T\n",
        "#     return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZXYW_erSi-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def forward_prop_for_pred(X, params):\n",
        "#     # Retrieve the parameters from the dictionairy \"parameters\"\n",
        "#     W1 = params[\"W1\"]\n",
        "#     b1 = params[\"b1\"]\n",
        "#     W2 = params[\"W2\"]\n",
        "#     b2 = params[\"b2\"]\n",
        "#     W3 = params[\"W3\"]\n",
        "#     b3 = params[\"b3\"]\n",
        "\n",
        "#     Z1 = tf.add(tf.matmul(W1, X), b1)\n",
        "#     A1 = tf.nn.relu(Z1)\n",
        "#     Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
        "#     A2 = tf.nn.relu(Z2)\n",
        "#     Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
        "\n",
        "#     return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtvc_-xeTMKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def predict(X, parameters):\n",
        "#     m = X.shape()\n",
        "#     W1 = tf.convert_to_tensor(params[\"W1\"])\n",
        "#     b1 = tf.convert_to_tensor(params[\"b1\"])\n",
        "#     W2 = tf.convert_to_tensor(params[\"W2\"])\n",
        "#     b2 = tf.convert_to_tensor(params[\"b2\"])\n",
        "#     W3 = tf.convert_to_tensor(params[\"W3\"])\n",
        "#     b3 = tf.convert_to_tensor(params[\"b3\"])\n",
        "\n",
        "#     parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\": W3, \"b3\": b3}\n",
        "\n",
        "#     var = tf.placeholder(\"float\", [m, 1])\n",
        "\n",
        "#     z3 = forward_prop_for_pred(X, params)\n",
        "#     p = tf.argmax(z3)\n",
        "\n",
        "#     sess = tf.Session()\n",
        "#     prediction = sess.run(p, feed_dict={x: X})\n",
        "\n",
        "#     return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmWKONtqMXul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.datasets import cifar100, mnist\n",
        "\n",
        "# (X_train_cifar100, y_train_cifar100), (X_test_cifar100, y_test_cifar100) = cifar100.load_data()\n",
        "# print(X_train_cifar100.shape)\n",
        "# print(X_test_cifar100.shape)\n",
        "\n",
        "# (X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
        "# X_train_mnist = X_train_mnist.reshape(60000, 28, 28, -1)\n",
        "# X_test_mnist = X_test_mnist.reshape(10000, 28, 28, -1)\n",
        "# print(X_train_mnist.shape)\n",
        "# print(X_test_mnist.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8hGagROUF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_cifar100 = ResNet101(input_shape=(32, 32, 3), classes=100)\n",
        "# model_cifar100.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# model_mnist = ResNet101(input_shape=(28, 28, 1), classes=10)\n",
        "# model_mnist.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHQbzAG4O2qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imshow(X_train_mnist[2].reshape(28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umy4zEBlQX0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # normalize image vectors\n",
        "# X_train_cifar100 = X_train_cifar100 / 255.0\n",
        "# X_test_cifar100 = X_test_cifar100 / 255.0\n",
        "\n",
        "# # convert training and test labels to one hot encoded matrices\n",
        "# y_train_cifar100 = convert_to_one_hot(y_train_cifar100, 100).T\n",
        "# y_test_cifar100 = convert_to_one_hot(y_test_cifar100, 100).T\n",
        "\n",
        "# print(\"number of training examples = \" + str(X_train_cifar100.shape[0]))\n",
        "# print(\"number of test examples = \" + str(X_test_cifar100.shape[0]))\n",
        "# print(\"X_train shape: \" + str(X_train_cifar100.shape))\n",
        "# print(\"y_train shape: \" + str(y_train_cifar100.shape))\n",
        "# print(\"X_test shape: \" + str(X_test_cifar100.shape))\n",
        "# print(\"y_test shape: \" + str(y_test_cifar100.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OELfx7u50aJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_cifar100.fit(X_train_cifar100, y_train_cifar100, epochs=20, batch_size=50)\n",
        "# predictions = model_cifar100.evaluate(X_test_cifar100, y_test_cifar100)\n",
        "\n",
        "# print(\"Loss: \" + str(predictions[0]))\n",
        "# print(\"Test Accuracy \" + str(predictions[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2waiSCUx0yqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_cifar100.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jin9UBm1AHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # normalize image vectors\n",
        "# X_train_mnist = X_train_mnist / 255.0\n",
        "# X_test_mnist = X_test_mnist / 255.0\n",
        "\n",
        "# # convert training and test labels to one hot encoded matrices\n",
        "# y_train_mnist = convert_to_one_hot(y_train_mnist, 10).T\n",
        "# y_test_mnist = convert_to_one_hot(y_test_mnist, 10).T\n",
        "\n",
        "# print (\"number of training examples = \" + str(X_train_mnist.shape[0]))\n",
        "# print (\"number of test examples = \" + str(X_test_mnist.shape[0]))\n",
        "# print (\"X_train shape: \" + str(X_train_mnist.shape))\n",
        "# print (\"Y_train shape: \" + str(y_train_mnist.shape))\n",
        "# print (\"X_test shape: \" + str(X_test_mnist.shape))\n",
        "# print (\"Y_test shape: \" + str(y_test_mnist.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK3f1TKQ1CuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_mnist.fit(X_train_mnist, y_train_mnist, epochs=20, batch_size=50)\n",
        "# predictions = model_mnist.evaluate(X_test_mnist, y_test_mnist)\n",
        "\n",
        "# print(\"Loss: \" + str(predictions[0]))\n",
        "# print(\"Test Accuracy: \" + str(predictions[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw2kjyA11YwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_mnist.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}